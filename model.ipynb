{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1):  embedding 层\n",
    "* transformaer 有两种embedding。一种是词的embedding,一种是位置的embedding。Word embedding就不多说了，pos embedding 是由facebook提出的。这里用pos embedding 的原因是机器翻译需要很强的顺序性，但是self-attention没有关注到顺序，所以加入pos embedding。在transformer里是将pos  embedding和word embedding 相加，得到最终的embedding。\n",
    "* pos embedding 的计算方法是\n",
    "\n",
    "    $PE_(pos, 2i) = sin(pos/1000^{2i/d_model})$\n",
    "    \n",
    "    $PE_(pos, 2i+1) = cos(pos/1000^{2i/d_model})$\n",
    "    \n",
    "    $pos$ 是在词在句子中的相对位置，$i$ 是pos embedding 中的相对位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, vocab_szie, emb_dim):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_szie, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, emb_dim, max_seq_len=200, dropout=0.1):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        pe = torch.zeros(max_seq_len, emb_dim)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, emb_dim, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / emb_dim)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1)) / emb_dim)))\n",
    "\n",
    "        # self.register_buffer可以将tensor注册成buffer\n",
    "        #  网络存储时也会将buffer存下，当网络load模型时，会将存储的模型的buffer也进行赋值。\n",
    "        pe = pe.unsqueeze(0) # word embedding shape为)(ba, seq_len, dim),这里为了后两维相同\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.emb_dim)\n",
    "\n",
    "        seq_len = x.size(1)\n",
    "        # 据说训练出来的pos embedding 和计算出来的embedding效果相当，所以这里不需要求导\n",
    "        pe = Variable(self.pe[:, :seq_len,:], requires_grad=False)\n",
    "\n",
    "        x = x + pe\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)：Attention\n",
    "\n",
    "#### Scaled Dot-Product Attention\n",
    "计算公式: $\\text{Attention}(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt d_k})V$\n",
    "\n",
    "Q, K, V 分别代表Query, Key, Value,论文中是这样解释这个公式: 通过$Q$和$K$的相似程度来确定$V$。除以$\\sqrt d_k$的原因是$Q$和$K$可能得到比较大的值，而有一些值特别小，而导致梯度过小。\n",
    "<img src=\"image/scaled_dot_product_attention_arch.png\"  height=\"400\" width=\"250\">\n",
    "    \n",
    "#### Multi-Head Attention\n",
    "\n",
    "将Q、K、V通过一个线性映射之后，分成 h 份，对每一份进行scaled dot-product attention效果更好。然后，把各个部分的结果合并起来，再次经过线性映射，得到最终的输出。这就是所谓的multi-head attention。\n",
    " <img src=\"image/multi_head_attention_arch.png\"  height=\"400\" width=\"250\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "    # 这里mask的在decoder的时候输入的，在训练的时候，不需要得到当前翻译词\n",
    "    # 后面的知识， 所以需要mask来表示哪些是后面的词。\n",
    "    # 把当前词后面的词的位置的值改为-1e9,这样后面的位置经过softmax就会接近于0\n",
    "    # 从而得不到后面的信息\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "\n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        # 经过线性映射，然后将q,k,v分为 n 份\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "\n",
    "        # transpose to get dimensions bs * N * seq_len * d_model\n",
    "        k = k.transpose(1, 2)\n",
    "        q = q.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        # calculate attention using function we will define next\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        # concatenate heads and put through final linear layer\n",
    "        concat = scores.transpose(1, 2).contiguous() \\\n",
    "            .view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3):  Position-wise Feed-Forward Networks\n",
    "计算公式: $FFN(x)=max(0,xW_1+b_1)W_2+b_2$\n",
    "\n",
    "先经过一个线性变换，然后经过relu,最后再经过线性变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # We set d_ff as a default to 2048\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4):  Layer Normalization\n",
    "\n",
    "我们对batch normalization 很熟悉，batch normalization在整个训练样本上计算均值和方差，然后对样本进行归一化。然而Layer Normalization是对每一个样本上计算均值和方差，然后进行归一化。也就是说每一个样本都是根据自己的方差和均值进行归一化的。\n",
    "\n",
    "\n",
    "pytorch 有已经实现了的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.size = d_model\n",
    "\n",
    "        # create two learnable parameters to calibrate normalisation\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        # nn.LayerNorm\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
    "               / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5): EncoderLayer\n",
    "* 在encoder的self-attention中，$Q、K、V$都来自同一个地方（相等），他们是上一层encoder的输出。对于第一层encoder，它们就是word embedding和positional encoding相加得到的输入。\n",
    "* $Q、K、V$三者的维度一样，即 $dq=dk=dv$。\n",
    "* 每一个encoder-layer都由self-attention 和 Position-wise Feed-Forward Networks 组成。\n",
    "* 含有残差操作\n",
    "<img src=\"image/encoder_layer.png\" width=\"250\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2, x2, x2, mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6): DecoderLayer\n",
    "* 在decoder的self-attention中，Q、K、V都来自于同一个地方（相等），它们是上一层decoder的输出。对于第一层decoder，它们就是word embedding和positional encoding相加得到的输入。\n",
    "* 在encoder-decoder attention中，Q来自于decoder的上一层的输出，K和V来自于encoder的输出，K和V是一样的。\n",
    "* Q、K、V三者的维度一样，即 $dq=dk=dv$。\n",
    "* 含有残差操作。\n",
    "<img src=\"image/decoder_layer.png\" height=\"300\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7): Encoder Decoder \n",
    "encoder 和decoder 都是分别由N个encoderLayer 和 decoderlayer组成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "   http://localhost:8888/notebooks/image/transfomer.png     return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8): Transformer\n",
    "只需把encoder 和 decoder组装在一起。\n",
    "<img src=\"image/transfomer.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        # print(\"DECODER\")\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二: 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import nltk\n",
    "import torch\n",
    "from torchtext import data\n",
    "import pandas as pd\n",
    "import params\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path):\n",
    "    data = []\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "    lang = []\n",
    "    lang2 = []\n",
    "\n",
    "    for idx, da in enumerate(data):\n",
    "        #         print(da)\n",
    "        d = da.split(\"\\t\")\n",
    "        lang.append(d[0].strip())\n",
    "        lang2.append(d[1].strip())\n",
    "    # print(lang[0:3])\n",
    "    #     print(lang2[0:3])\n",
    "    return lang, lang2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cn_tokenize(sentence):\n",
    "    seg_list = jieba.cut(sentence)\n",
    "#     print(\", \".join(seg_list))\n",
    "    return [toekn for toekn in  seg_list]\n",
    "# cn_tokenize(cn_lang[307])\n",
    "\n",
    "def en_tokenize(sentence):\n",
    "    seg_list = nltk.word_tokenize(sentence)\n",
    "    return [token for token in seg_list]\n",
    "# en_tokenize(en_lang[307])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet(SRC, TRG, lang, lang2, batch_size):\n",
    "    raw_data = {'src': lang, 'trg': lang2}\n",
    "    df = pd.DataFrame(raw_data, columns=['src', 'trg'])\n",
    "\n",
    "    if not os.path.exists(\"./data/train.csv\") or not os.path.exists(\"./data/test.csv\"):\n",
    "        df = shuffle(df) # 打乱数据\n",
    "        test_df = df[:params.test_nums] # 得到后test nums 个数据做测试\n",
    "        train_df = df[params.test_nums:] # 剩下的做训练\n",
    "        test_df.to_csv(\"data/test.csv\", index=False, encoding='utf-8')\n",
    "        train_df.to_csv(\"data/train.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "    data_fields = [('src', SRC), ('trg', TRG)]\n",
    "    train = data.TabularDataset('./data/train.csv', format='csv', fields=data_fields, skip_header=True)\n",
    "    test = data.TabularDataset('./data/test.csv', format='csv', fields=data_fields, skip_header=True)\n",
    "\n",
    "    if params.is_cuda:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    train_iter = data.Iterator(train, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                                      batch_size=params.batch_size,device=device)\n",
    "    test_iter = data.Iterator(test, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                               batch_size=params.test_batch_size, device=device)\n",
    "\n",
    "    SRC.build_vocab(train, min_freq=params.src_min_freq)\n",
    "    TRG.build_vocab(train, min_freq=params.trg_min_freq)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFiled(path, batch_size=1):\n",
    "    en_lang, cn_lang = getData(path)\n",
    "    SRC = data.Field(lower=True, tokenize=en_tokenize, init_token='<sos>', eos_token='<eos>')\n",
    "    # trg是中文\n",
    "    TRG = data.Field(tokenize=cn_tokenize, eos_token='<eos>', init_token='<sos>')\n",
    "    createDataSet(SRC, TRG, en_lang, cn_lang, batch_size)\n",
    "\n",
    "    return SRC, TRG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedData(path, batch_size):\n",
    "    # path = \"./data/en-cn.txt\"\n",
    "    en_lang, cn_lang = getData(path)\n",
    "    SRC = data.Field(lower=True, tokenize=en_tokenize, init_token='<sos>', eos_token='<eos>')\n",
    "    # trg是中文\n",
    "    TRG = data.Field(tokenize=cn_tokenize, eos_token='<eos>', init_token='<sos>')\n",
    "    createDataSet(SRC, TRG, en_lang, cn_lang, batch_size)\n",
    "    train_iter, test_iter = createDataSet(SRC, TRG, en_lang, cn_lang, batch_size)\n",
    "    return SRC, TRG, train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"./data/en-cn.txt\"\n",
    "# preparedData(path, 1)\n",
    "# en_lang, cn_lang = getData(path)\n",
    "# SRC = data.Field(lower=True, tokenize=en_tokenize, init_token='<sos>', eos_token='<eos>')\n",
    "# # trg是中文\n",
    "# TRG = data.Field(tokenize=cn_tokenize, eos_token='<eos>', init_token='<sos>')\n",
    "# train_iter, test_iter = createDataSet(SRC, TRG, en_lang, cn_lang, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三: 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import params\n",
    "from tensorboardX import SummaryWriter\n",
    "import mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trg_vocal_len:  2316\n",
      "src_vocab_len:  1910\n",
      "0   0\n",
      "2   2\n",
      "3   3\n"
     ]
    }
   ],
   "source": [
    "SRC, TRG,  train_iter, test_iter = preparedData(params.data_path, params.batch_size)\n",
    "src_pad = SRC.vocab.stoi['<pad>']\n",
    "trg_pad = TRG.vocab.stoi['<pad>']\n",
    "print('trg_vocal_len: ', len(TRG.vocab))\n",
    "print('src_vocab_len: ', len(SRC.vocab))\n",
    "print(SRC.vocab.stoi['<unk>'], \" \", TRG.vocab.stoi['<unk>'])\n",
    "print(SRC.vocab.stoi['<sos>'], \" \", TRG.vocab.stoi['<sos>'])\n",
    "print(SRC.vocab.stoi['<eos>'], \" \", TRG.vocab.stoi['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(len(SRC.vocab), len(TRG.vocab), params.d_model, params.n_layers, params.heads, params.dropout)\n",
    "if params.is_cuda:\n",
    "    model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params.lr, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "begin training model\n",
      "epoch:1 train_loss:3.9178114094620193 test_loss:3.4168846864700315 time:577.90\n",
      "epoch:2 train_loss:3.269623666977155 test_loss:3.1415644764900206 time:555.91\n",
      "epoch:3 train_loss:2.967221039538529 test_loss:2.943972107887268 time:553.65\n",
      "epoch:4 train_loss:2.717956202539254 test_loss:2.8046658070087434 time:559.36\n",
      "epoch:5 train_loss:2.4985898237825914 test_loss:2.7050731492042543 time:555.36\n",
      "epoch:6 train_loss:2.3037051836125437 test_loss:2.627584369182587 time:548.67\n",
      "epoch:7 train_loss:2.1178745956137863 test_loss:2.5776197934150695 time:568.21\n",
      "epoch:8 train_loss:1.9447398918872025 test_loss:2.562746128082275 time:686.68\n",
      "epoch:9 train_loss:1.7756196801955308 test_loss:2.5576643748283385 time:828.80\n",
      "epoch:10 train_loss:1.6192045680570484 test_loss:2.550012111902237 time:775.78\n",
      "epoch:11 train_loss:1.4661846965281116 test_loss:2.58151980304718 time:692.78\n",
      "epoch:12 train_loss:1.3258367551326358 test_loss:2.620600311756134 time:655.46\n",
      "epoch:13 train_loss:1.1966972584972082 test_loss:2.659133913040161 time:669.66\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-efbef6cf6f73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrg_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\nbegin training model\")\n",
    "model.train()\n",
    "if os.path.exists(\"models/tfs.pkl\"):\n",
    "    model.load_state_dict(torch.load(\"models/tfs.pkl\"))\n",
    "\n",
    "best_loss = None\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(params.epochs):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    total_loss = 0.0\n",
    "    step = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        # print(batch)\n",
    "        src = batch.src.transpose(0, 1)\n",
    "        trg = batch.trg.transpose(0, 1)\n",
    "\n",
    "        trg_input = trg[:, :-1]\n",
    "        src_mask, trg_mask = mask.createMask(src, src_pad, trg_input, trg_pad)\n",
    "\n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        _, pred = torch.max(preds, 2)\n",
    "        # print(preds.size())\n",
    "        # print(pred.size())\n",
    "        # print(pred[0, :].size())\n",
    "        # print(trg[0,1:].size())\n",
    "#         print(pred[0,:].cpu().numpy())\n",
    "#         print(trg[0,1:].cpu().numpy())\n",
    "        # exit(1)\n",
    "        ys = trg[:, 1:].contiguous().view(-1)\n",
    "        if params.is_cuda:\n",
    "            params = ys.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=trg_pad)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        step = i+1\n",
    "        # print(src.size())\n",
    "        # print(trg.size())\n",
    "        # print(trg_input.size())\n",
    "        # print(src_mask.size())\n",
    "        # print(trg_mask.size())\n",
    "        # print(preds.size())\n",
    "        # print(ys.size())\n",
    "        # exit(1)\n",
    "        # print(loss.item())\n",
    "        # break\n",
    "    test_total_loss = 0.0\n",
    "    test_total_step = 0\n",
    "    for i, batch in enumerate(test_iter):\n",
    "        # print(batch)\n",
    "        src = batch.src.transpose(0, 1)\n",
    "        trg = batch.trg.transpose(0, 1)\n",
    "\n",
    "        trg_input = trg[:, :-1]\n",
    "        src_mask, trg_mask = mask.createMask(src, src_pad, trg_input, trg_pad)\n",
    "\n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        _, pred = torch.max(preds, 2)\n",
    "        # print(pred[0, :].cpu().numpy())\n",
    "        # print(trg[0, 1:].cpu().numpy())\n",
    "        # exit(1)\n",
    "        ys = trg[:, 1:].contiguous().view(-1)\n",
    "        if params.is_cuda:\n",
    "            params = ys.cuda()\n",
    "\n",
    "        loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=trg_pad)\n",
    "        test_total_loss += loss.item()\n",
    "        test_total_step = i + 1\n",
    "        # print(src.size())\n",
    "        # print(trg.size())\n",
    "        # print(trg_input.size())\n",
    "        # print(src_mask.size())\n",
    "        # print(trg_mask.size())\n",
    "        # print(preds.size())\n",
    "        # print(ys.size())\n",
    "        # exit(1)\n",
    "        # print(loss.item())\n",
    "\n",
    "        # break\n",
    "\n",
    "    writer.add_scalar('scalar/train_loss', total_loss/step, epoch)\n",
    "    writer.add_scalar('scalar/test_loss', test_total_loss/test_total_step, epoch)\n",
    "    print(\"epoch:{} train_loss:{} test_loss:{} time:{:.2f}\".format(epoch+1, total_loss/step, test_total_loss/test_total_step, time.time()-start))\n",
    "    if best_loss is None:\n",
    "        best_loss = test_total_loss/test_total_step\n",
    "        torch.save(model.state_dict(), \"models/tfs.pkl\")\n",
    "    if best_loss > test_total_loss/test_total_step :\n",
    "        best_loss = test_total_loss/test_total_step\n",
    "        torch.save(model.state_dict(), \"models/tfs.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"training end!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四: 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from new_process import createDataSet, getData, preparedData\n",
    "import params\n",
    "from model import Transformer\n",
    "from torchtext import data\n",
    "import torch\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "import mask\n",
    "from performance import Performance\n",
    "from my_optim import ScheduledOptim\n",
    "\n",
    "SRC, TRG,  train_iter, test_iter = preparedData(params.data_path, params.eval_batch_size)\n",
    "src_pad = SRC.vocab.stoi['<pad>']\n",
    "trg_pad = TRG.vocab.stoi['<pad>']\n",
    "model = Transformer(len(SRC.vocab), len(TRG.vocab), params.d_model, params.n_layers, params.heads, params.dropout)\n",
    "if params.is_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# print(model)\n",
    "print('trg_vocal_len: ', len(TRG.vocab))\n",
    "print('src_vocab_len: ', len(SRC.vocab))\n",
    "\n",
    "model.load_state_dict(torch.load('models/tfs.pkl'))\n",
    "model.eval()\n",
    "\n",
    "cnt = 10\n",
    "for i, batch in enumerate(train_iter):\n",
    "    # print(batch)\n",
    "    src = batch.src.transpose(0, 1)\n",
    "    trg = batch.trg.transpose(0, 1)\n",
    "    print(src.size())\n",
    "    print(trg.size())\n",
    "    # print(src)\n",
    "    print(\"trg: \", trg)\n",
    "    trg_input = trg[:, 0].unsqueeze(1)\n",
    "    # print(trg_input.size())\n",
    "\n",
    "    src_mask = None\n",
    "    trg_mask = None\n",
    "    for i in range(params.max_len):\n",
    "        preds = model(src, trg_input, src_mask, trg_mask)\n",
    "        # print(\"pred \", torch.max(preds, 2)[1])\n",
    "        pred = torch.max(preds, 2)[1]\n",
    "        trg_input = torch.cat((trg_input, pred[:, i].unsqueeze(1)), dim=1)\n",
    "        # print(pred[:, i].unsqueeze(1))\n",
    "    print(\"pred:\", trg_input)\n",
    "    cnt -= 1\n",
    "    if cnt==0:\n",
    "        break\n",
    "    # break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
